{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This notebook is inspired from the kaggle notebook at: \n",
    "https://www.kaggle.com/code/awsaf49/vinbigdata-cxr-ad-yolov5-14-class-train?kernelSessionId=52422980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import logging\n",
    "import sys\n",
    "from ultralytics import YOLO\n",
    "import albumentations as A\n",
    "import random\n",
    "# from ultralytics.engine.callbacks import Callbacks\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Path('/root')  #Path(\"/mnt/shared_dataset\")\n",
    "root = base / \"YOLO\"\n",
    "dicom_dir = base / \"physionet.org/files/vindr-cxr/1.0.0/train\"\n",
    "dicom_test_dir = base / \"physionet.org/files/vindr-cxr/1.0.0/test\"\n",
    "\n",
    "png_dir = root / \"images\"\n",
    "label_dir = root / \"labels\"\n",
    "test_dir = png_dir / \"test\"\n",
    "yaml_path = root / \"yolov12/my-yolov12.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in ['train', 'val']:\n",
    "    os.makedirs(os.path.join(png_dir,sub), exist_ok=True)\n",
    "    os.makedirs(os.path.join(label_dir, sub), exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = root / \"yolo_aggregated.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "df[\"image_path\"] = df[\"image_id\"].apply(lambda x: f\"YOLO/images/train/{x}.png\")  # adjust path/format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_train = png_dir/\"train\"\n",
    "actual_pngs = {p.stem for p in (png_train).glob(\"*.png\")}\n",
    "\n",
    "# Compare with image IDs in dataframe (after No finding drop)\n",
    "df_ids = set(df[\"image_id\"])\n",
    "missing_png_ids = df_ids - actual_pngs\n",
    "log_dir = \"log_dir\"\n",
    "log_file = os.path.join(log_dir, \"missing_from_disk_after_drop.txt\")\n",
    "\n",
    "if missing_png_ids:\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    if not os.path.exists(log_file):\n",
    "        with open(log_file, \"w\") as f:\n",
    "            for mid in sorted(missing_png_ids):\n",
    "                f.write(mid + \"\\n\")\n",
    "    logging.warning(f\"{len(missing_png_ids)} image_ids missing as PNGs on disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class_id'] = df['class_name'].astype('category').cat.codes\n",
    "class_map = dict(enumerate(df['class_name'].astype('category').cat.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=5)\n",
    "df['fold'] = -1\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "for fold, (_, val_idx) in enumerate(gkf.split(df, groups=df['image_id'])):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "val_fold = 0  # 20% validation (1 out of 5 folds)\n",
    "\n",
    "df_ids = set(df[\"image_id\"])\n",
    "train_ids = set(df[df['fold'] != val_fold]['image_id'].apply(lambda x: Path(x).stem))\n",
    "val_ids = set(df[df['fold'] == val_fold]['image_id'].apply(lambda x: Path(x).stem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "print(f\"(Labels) LEN OF TRAIN DIR: {len(os.listdir('../labels/train'))}  |  LEN OF VAL DIR: {len(os.listdir('../labels/val'))}\")\n",
    "print(f\"üìä TRAIN SIZE: {len(train_ids)} | VAL SIZE: {len(val_ids)}\", file=sys.stderr)\n",
    "\n",
    "missing = []\n",
    "for name in val_ids:\n",
    "    path = os.path.join((label_dir/\"val\"), f\"{name}.txt\")\n",
    "    if not os.path.exists(path):\n",
    "        missing.append(name)\n",
    "\n",
    "# === Result\n",
    "if not missing:\n",
    "    print(\"‚úÖ All .txt files exist.\")\n",
    "else:\n",
    "    print(f\"‚ùå Missing {len(missing)} .txt files:\")\n",
    "    for m in missing:\n",
    "        print(\"  \", m)\n",
    "# === Log ===\n",
    "summary_path = \"log_dir/train_val_summary.txt\"\n",
    "with open(summary_path, \"w\") as f:\n",
    "    f.write(f\"TRAIN SIZE: {len(train_ids)}\\nVAL SIZE: {len(val_ids)}\\n\")\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_content = f\"\"\"# Lung Disease Dataset\n",
    "path: {root}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "nc: {len(class_map)}\n",
    "names: {list(class_map.values())}\n",
    "\"\"\"\n",
    "print(yaml_content)\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    f.write(yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = Path(f\"{root}/yolov12/runs/detect/latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo12m.pt\")\n",
    "# print(f\"1 using {model}\")\n",
    "results = model.train(data = yaml_path, epochs=10, imgsz=640, batch = 16 ,device='cpu' , save = True, cache = True, project=run ,name=\"train\") # callbacks = callbacks,\n",
    "print(f\"2 done training. Results saved in: {results.save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_run = run / \"train\"\n",
    "weights_path = last_run / \"weights\" / \"best.pt\"\n",
    "if not weights_path.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå Weights not found at {weights_path}\")\n",
    "\n",
    "print(f\"üß™ Testing first 100 .png images from: {weights_path}\")\n",
    "\n",
    "test_images = sorted(test_dir.glob(\"*.png\"))[:100]  # replace with your real test_dir\n",
    "model = YOLO(str(weights_path))\n",
    "results = model(\n",
    "    [str(p) for p in test_images],\n",
    "    save=True,\n",
    "    conf=0.25,\n",
    "    save_dir=f\"{run}/first_100_inference\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
