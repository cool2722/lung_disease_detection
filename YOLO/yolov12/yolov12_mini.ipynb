{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f91d9d",
   "metadata": {},
   "source": [
    "Note: This notebook is inspired from the kaggle notebook at: \n",
    "https://www.kaggle.com/code/awsaf49/vinbigdata-cxr-ad-yolov5-14-class-train?kernelSessionId=52422980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b347bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae4130c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_DIR = Path(r\"c:/Users/jsayed/Downloads/DHBW/lung-disease-detection\")\n",
    "DATASET_DIR = BASE_DIR / \"dataset\"\n",
    "\n",
    "IMAGES_ROOT = DATASET_DIR / \"images\"\n",
    "LABELS_ROOT = DATASET_DIR / \"labels\"\n",
    "YAML_PATH = BASE_DIR / \"YOLO/yolov12/my-yolov12.yaml\"\n",
    "\n",
    "TRAIN_IMAGES_DIR = IMAGES_ROOT / \"train\"\n",
    "VAL_IMAGES_DIR = IMAGES_ROOT / \"val\"\n",
    "TEST_IMAGES_DIR = IMAGES_ROOT / \"test\"\n",
    "\n",
    "TRAIN_LABELS_DIR = LABELS_ROOT / \"train\"\n",
    "VAL_LABELS_DIR = LABELS_ROOT / \"val\"\n",
    "\n",
    "SOURCE_IMAGES_DIR = TRAIN_IMAGES_DIR if TRAIN_IMAGES_DIR.exists() else IMAGES_ROOT\n",
    "SOURCE_LABELS_DIR = TRAIN_LABELS_DIR if TRAIN_LABELS_DIR.exists() else LABELS_ROOT\n",
    "\n",
    "IMAGE_EXTENSIONS = (\".png\", \".jpg\", \".jpeg\")\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "YAML_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb301561",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for split in [\"train\", \"val\"]:\n",
    "    (IMAGES_ROOT / split).mkdir(parents=True, exist_ok=True)\n",
    "    (LABELS_ROOT / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TEST_IMAGES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if SOURCE_IMAGES_DIR == IMAGES_ROOT:\n",
    "    TRAIN_IMAGES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    for image_path in IMAGES_ROOT.glob(\"*\"):\n",
    "        if image_path.is_file() and image_path.suffix.lower() in IMAGE_EXTENSIONS:\n",
    "            destination = TRAIN_IMAGES_DIR / image_path.name\n",
    "            if not destination.exists():\n",
    "                shutil.move(image_path, destination)\n",
    "    SOURCE_IMAGES_DIR = TRAIN_IMAGES_DIR\n",
    "\n",
    "if SOURCE_LABELS_DIR == LABELS_ROOT:\n",
    "    TRAIN_LABELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    for label_path in LABELS_ROOT.glob(\"*.txt\"):\n",
    "        destination = TRAIN_LABELS_DIR / label_path.name\n",
    "        if not destination.exists():\n",
    "            shutil.move(label_path, destination)\n",
    "    SOURCE_LABELS_DIR = TRAIN_LABELS_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce773022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_path = DATASET_DIR / \"yolo_aggregated.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "def resolve_image_path(image_id: str) -> str:\n",
    "    for extension in IMAGE_EXTENSIONS:\n",
    "        candidates = (\n",
    "            TRAIN_IMAGES_DIR / f\"{image_id}{extension}\",\n",
    "            VAL_IMAGES_DIR / f\"{image_id}{extension}\",\n",
    "            SOURCE_IMAGES_DIR / f\"{image_id}{extension}\",\n",
    "        )\n",
    "        for candidate in candidates:\n",
    "            if candidate.exists():\n",
    "                return str(candidate)\n",
    "    return str(TRAIN_IMAGES_DIR / f\"{image_id}.png\")\n",
    "\n",
    "df[\"image_path\"] = df[\"image_id\"].apply(resolve_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3563a598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>image_path</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>class_id</th>\n",
       "      <th>x_mid</th>\n",
       "      <th>y_mid</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005e8e3701dfb1dd93d53e2ff537b6e</td>\n",
       "      <td>Lung Opacity</td>\n",
       "      <td>0.294670</td>\n",
       "      <td>0.191344</td>\n",
       "      <td>0.391689</td>\n",
       "      <td>0.289294</td>\n",
       "      <td>c:\\Users\\jsayed\\Downloads\\DHBW\\lung-disease-de...</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>11</td>\n",
       "      <td>0.34318</td>\n",
       "      <td>0.240319</td>\n",
       "      <td>0.097020</td>\n",
       "      <td>0.097950</td>\n",
       "      <td>0.009503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0007d316f756b3fa0baea2ff514ce945</td>\n",
       "      <td>Pleural thickening</td>\n",
       "      <td>0.355324</td>\n",
       "      <td>0.235103</td>\n",
       "      <td>0.428676</td>\n",
       "      <td>0.295741</td>\n",
       "      <td>c:\\Users\\jsayed\\Downloads\\DHBW\\lung-disease-de...</td>\n",
       "      <td>2880</td>\n",
       "      <td>2304</td>\n",
       "      <td>17</td>\n",
       "      <td>0.39200</td>\n",
       "      <td>0.265422</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>0.060637</td>\n",
       "      <td>0.004448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id          class_name     x_min     y_min  \\\n",
       "0  0005e8e3701dfb1dd93d53e2ff537b6e        Lung Opacity  0.294670  0.191344   \n",
       "1  0007d316f756b3fa0baea2ff514ce945  Pleural thickening  0.355324  0.235103   \n",
       "\n",
       "      x_max     y_max                                         image_path  \\\n",
       "0  0.391689  0.289294  c:\\Users\\jsayed\\Downloads\\DHBW\\lung-disease-de...   \n",
       "1  0.428676  0.295741  c:\\Users\\jsayed\\Downloads\\DHBW\\lung-disease-de...   \n",
       "\n",
       "   height  width  class_id    x_mid     y_mid         w         h      area  \n",
       "0    3072   3072        11  0.34318  0.240319  0.097020  0.097950  0.009503  \n",
       "1    2880   2304        17  0.39200  0.265422  0.073352  0.060637  0.004448  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ad9289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"class_id\"] = df[\"class_name\"].astype(\"category\").cat.codes\n",
    "class_map = dict(enumerate(df[\"class_name\"].astype(\"category\").cat.categories))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "507f3a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "df[\"fold\"] = -1\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "for fold, (_, val_idx) in enumerate(gkf.split(df, groups=df[\"image_id\"])):\n",
    "    df.loc[val_idx, \"fold\"] = fold\n",
    "\n",
    "val_fold = 0  # 20% validation (1 out of 5 folds)\n",
    "\n",
    "df_ids = set(df[\"image_id\"])\n",
    "train_ids = {\n",
    "    Path(image_id).stem for image_id in df[df[\"fold\"] != val_fold][\"image_id\"]\n",
    "}\n",
    "val_ids = {\n",
    "    Path(image_id).stem for image_id in df[df[\"fold\"] == val_fold][\"image_id\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bc7aa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def move_label_to_val(image_id: str) -> None:\n",
    "    label_name = f\"{image_id}.txt\"\n",
    "    for candidate in (\n",
    "        VAL_LABELS_DIR / label_name,\n",
    "        TRAIN_LABELS_DIR / label_name,\n",
    "        SOURCE_LABELS_DIR / label_name,\n",
    "        LABELS_ROOT / label_name,\n",
    "    ):\n",
    "        if candidate.exists():\n",
    "            if candidate.parent != VAL_LABELS_DIR:\n",
    "                VAL_LABELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.move(candidate, VAL_LABELS_DIR / label_name)\n",
    "            return\n",
    "\n",
    "def move_image_to_val(image_id: str) -> None:\n",
    "    for extension in IMAGE_EXTENSIONS:\n",
    "        image_name = f\"{image_id}{extension}\"\n",
    "        for candidate in (\n",
    "            VAL_IMAGES_DIR / image_name,\n",
    "            TRAIN_IMAGES_DIR / image_name,\n",
    "            SOURCE_IMAGES_DIR / image_name,\n",
    "            IMAGES_ROOT / image_name,\n",
    "        ):\n",
    "            if candidate.exists():\n",
    "                if candidate.parent != VAL_IMAGES_DIR:\n",
    "                    VAL_IMAGES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "                    shutil.move(candidate, VAL_IMAGES_DIR / candidate.name)\n",
    "                return\n",
    "\n",
    "for image_id in val_ids:\n",
    "    move_label_to_val(image_id)\n",
    "    move_image_to_val(image_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c94f400e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels/val contains 2149 label files\n",
      "images/val contains 2149 image files\n",
      "Train set size: 3450 | Validation set size: 862\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_label_count = len([path for path in VAL_LABELS_DIR.glob(\"*.txt\") if path.is_file()])\n",
    "val_image_count = len([\n",
    "    path\n",
    "    for path in VAL_IMAGES_DIR.iterdir()\n",
    "    if path.is_file() and path.suffix.lower() in IMAGE_EXTENSIONS\n",
    "])\n",
    "\n",
    "print(f\"labels/val contains {val_label_count} label files\")\n",
    "print(f\"images/val contains {val_image_count} image files\")\n",
    "\n",
    "missing_labels = [\n",
    "    image_id\n",
    "    for image_id in val_ids\n",
    "    if not any(\n",
    "        path.exists()\n",
    "        for path in (\n",
    "            VAL_LABELS_DIR / f\"{image_id}.txt\",\n",
    "            TRAIN_LABELS_DIR / f\"{image_id}.txt\",\n",
    "            LABELS_ROOT / f\"{image_id}.txt\",\n",
    "        )\n",
    "    )\n",
    "]\n",
    "if missing_labels:\n",
    "    print(f\"Missing labels for {len(missing_labels)} validation images: {missing_labels[:5]} ...\")\n",
    "\n",
    "missing_images = []\n",
    "for image_id in val_ids:\n",
    "    candidates = []\n",
    "    for extension in IMAGE_EXTENSIONS:\n",
    "        candidates.extend([\n",
    "            VAL_IMAGES_DIR / f\"{image_id}{extension}\",\n",
    "            TRAIN_IMAGES_DIR / f\"{image_id}{extension}\",\n",
    "            SOURCE_IMAGES_DIR / f\"{image_id}{extension}\",\n",
    "            IMAGES_ROOT / f\"{image_id}{extension}\",\n",
    "        ])\n",
    "    if not any(path.exists() for path in candidates):\n",
    "        missing_images.append(image_id)\n",
    "\n",
    "if missing_images:\n",
    "    print(f\"Missing images for {len(missing_images)} validation IDs: {missing_images[:5]} ...\")\n",
    "\n",
    "print(f\"Train set size: {len(train_ids)} | Validation set size: {len(val_ids)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4544bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Lung Disease Dataset\n",
      "path: c:\\Users\\jsayed\\Downloads\\DHBW\\lung-disease-detection\\dataset\n",
      "train: images/train\n",
      "val: images/val\n",
      "test: images/test\n",
      "nc: 22\n",
      "names: ['Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Clavicle fracture', 'Consolidation', 'Edema', 'Emphysema', 'Enlarged PA', 'ILD', 'Infiltration', 'Lung Opacity', 'Lung cavity', 'Lung cyst', 'Mediastinal shift', 'Nodule/Mass', 'Other lesion', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis', 'Rib fracture']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "yaml_content = f\"\"\"# Lung Disease Dataset\n",
    "path: {DATASET_DIR}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "nc: {len(class_map)}\n",
    "names: {list(class_map.values())}\n",
    "\"\"\"\n",
    "print(yaml_content)\n",
    "YAML_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(YAML_PATH, \"w\") as f:\n",
    "    f.write(yaml_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a0eea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run = BASE_DIR / \"YOLO/yolov12/runs/detect/latest\"\n",
    "run.parent.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167ea5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = YOLO(\"yolo12m.pt\")\n",
    "print(f\"Using model: {model.model_name}\")\n",
    "results = model.train(\n",
    "    data=YAML_PATH,\n",
    "    epochs=10,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    device=DEVICE,\n",
    "    save=True,\n",
    "    cache=True,\n",
    "    project=run,\n",
    "    name=\"train\",\n",
    ")\n",
    "print(f\"Training complete. Results saved in: {results.save_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935411b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "last_run = run / \"train\"\n",
    "weights_path = last_run / \"weights\" / \"best.pt\"\n",
    "if not weights_path.exists():\n",
    "    raise FileNotFoundError(f\"Weights not found at {weights_path}\")\n",
    "\n",
    "print(f\"Running inference on first 100 PNG images using weights: {weights_path}\")\n",
    "\n",
    "test_images = sorted(TEST_IMAGES_DIR.glob(\"*.png\"))[:100]\n",
    "model = YOLO(str(weights_path))\n",
    "results = model(\n",
    "    [str(path) for path in test_images],\n",
    "    save=True,\n",
    "    conf=0.25,\n",
    "    save_dir=f\"{run}/first_100_inference\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cleanenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
