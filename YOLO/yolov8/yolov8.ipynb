{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This notebook is inspired from the kaggle notebook at: \n",
    "https://www.kaggle.com/code/awsaf49/vinbigdata-cxr-ad-yolov5-14-class-train?kernelSessionId=52422980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import logging\n",
    "import sys\n",
    "from ultralytics import YOLO\n",
    "import albumentations as A\n",
    "from ultralytics.data.augment import LetterBox\n",
    "import random, shutil\n",
    "# from ultralytics.engine.callbacks import Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Path('/root')  #Path(\"/mnt/shared_dataset\")\n",
    "root = base / \"YOLO\"\n",
    "dicom_dir = base / \"physionet.org/files/vindr-cxr/1.0.0/train\"\n",
    "dicom_test_dir = base / \"physionet.org/files/vindr-cxr/1.0.0/test\"\n",
    "\n",
    "png_dir = root / \"images\"\n",
    "label_dir = root / \"labels\"\n",
    "test_dir = png_dir / \"test\"\n",
    "yaml_path = root / \"yolov8/my-yolov8.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in ['train', 'val']:\n",
    "    os.makedirs(os.path.join(png_dir,sub), exist_ok=True)\n",
    "    os.makedirs(os.path.join(label_dir, sub), exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = root / \"yolo_aggregated.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "df[\"image_path\"] = df[\"image_id\"].apply(lambda x: f\"YOLO/images/train/{x}.png\")  # adjust path/format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_train = png_dir/\"train\"\n",
    "actual_pngs = {p.stem for p in (png_train).glob(\"*.png\")}\n",
    "\n",
    "# Compare with image IDs in dataframe (after No finding drop)\n",
    "df_ids = set(df[\"image_id\"])\n",
    "missing_png_ids = df_ids - actual_pngs\n",
    "log_dir = \"log_dir\"\n",
    "log_file = os.path.join(log_dir, \"missing_from_disk_after_drop.txt\")\n",
    "\n",
    "if missing_png_ids:\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    if not os.path.exists(log_file):\n",
    "        with open(log_file, \"w\") as f:\n",
    "            for mid in sorted(missing_png_ids):\n",
    "                f.write(mid + \"\\n\")\n",
    "    logging.warning(f\"{len(missing_png_ids)} image_ids missing as PNGs on disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class_id'] = df['class_name'].astype('category').cat.codes\n",
    "class_map = dict(enumerate(df['class_name'].astype('category').cat.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=5)\n",
    "df['fold'] = -1\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "for fold, (_, val_idx) in enumerate(gkf.split(df, groups=df['image_id'])):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "val_fold = 0  # 20% validation (1 out of 5 folds)\n",
    "\n",
    "df_ids = set(df[\"image_id\"])\n",
    "train_ids = set(df[df['fold'] != val_fold]['image_id'].apply(lambda x: Path(x).stem))\n",
    "val_ids = set(df[df['fold'] == val_fold]['image_id'].apply(lambda x: Path(x).stem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_fold = 0\n",
    "# df_ids = set(df[\"image_id\"])\n",
    "# train_ids = set(df[df['fold'] != val_fold]['image_id'])\n",
    "# val_ids = set(df[df['fold'] == val_fold]['image_id'])\n",
    "\n",
    "# print(f\"length of train set: {len(train_ids)} & val set: {len(val_ids)}\")\n",
    "# print(f\"üìä TRAIN SIZE: {len(train_ids)} | VAL SIZE: {len(val_ids)}\", file=sys.stderr)\n",
    "# summary_path = \"log_dir/train_val_summary.txt\"\n",
    "# with open(summary_path, \"w\") as f:\n",
    "#     f.write(f\"TRAIN SIZE: {len(train_ids)}\\nVAL SIZE: {len(val_ids)}\\n\")\n",
    "\n",
    "# print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = Path(f\"{label_dir}/train\")\n",
    "labels_val = Path(f\"{label_dir}/val\")\n",
    "labels_val.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for img_id in val_ids:\n",
    "    src = labels_train / f\"{img_id}.txt\"\n",
    "    dst = labels_val / f\"{img_id}.txt\"\n",
    "    if src.exists():\n",
    "        shutil.move(src, dst)\n",
    "\n",
    "# === Reporting ===\n",
    "moved = len([f for f in labels_val.glob(\"*.txt\")])\n",
    "print(f\"‚úÖ Moved {moved} label files to labels/val/\")\n",
    "\n",
    "missing = [img_id for img_id in val_ids if not (labels_train / f\"{img_id}.txt\").exists()]\n",
    "if missing:\n",
    "    print(f\"‚ö†Ô∏è Missing {len(missing)} label files for val set: {missing[:5]} ...\")\n",
    "\n",
    "print(f\"length of train set: {len(train_ids)} & val set: {len(val_ids)}\")\n",
    "print(f\"üìä TRAIN SIZE: {len(train_ids)} | VAL SIZE: {len(val_ids)}\", file=sys.stderr)\n",
    "\n",
    "# === Log ===\n",
    "summary_path = \"log_dir/train_val_summary.txt\"\n",
    "with open(summary_path, \"w\") as f:\n",
    "    f.write(f\"TRAIN SIZE: {len(train_ids)}\\nVAL SIZE: {len(val_ids)}\\n\")\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# albumentations_transform = A.Compose([\n",
    "#     A.Rotate(limit=5, p=0.7),\n",
    "#     A.HorizontalFlip(p=0.5),\n",
    "#     A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=0, p=0.5),\n",
    "#     A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),\n",
    "#     A.GaussNoise(var_limit=(10.0, 50.0), p=0.4),\n",
    "#     A.MotionBlur(blur_limit=3, p=0.2),\n",
    "# ],\n",
    "#     bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'], min_visibility=0.3)\n",
    "# )\n",
    "\n",
    "# class AlbumentationsCallback(Callbacks):\n",
    "#     def on_preprocess_batch(self, trainer):\n",
    "#         for sample in trainer.batch:\n",
    "#             if random.random() < 0.1:  #  10% chance to skip augmentation\n",
    "#                 continue  # keep image and labels as-is\n",
    "\n",
    "#             img = sample['img']\n",
    "#             bboxes = sample['bboxes']\n",
    "#             cls = sample['cls']\n",
    "\n",
    "#             bboxes_list = [bbox.tolist() for bbox in bboxes]\n",
    "#             cls_list = cls.tolist()\n",
    "\n",
    "#             aug = albumentations_transform(image=img, bboxes=bboxes_list, class_labels=cls_list)\n",
    "\n",
    "#             sample['img'] = aug['image']\n",
    "#             sample['bboxes'] = aug['bboxes']\n",
    "#             sample['cls'] = aug['class_labels']\n",
    "\n",
    "\n",
    "# callbacks = AlbumentationsCallback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_content = f\"\"\"# Lung Disease Dataset\n",
    "path: {root}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "nc: {len(class_map)}\n",
    "names: {list(class_map.values())}\n",
    "\"\"\"\n",
    "print(yaml_content)\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    f.write(yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = Path(f\"{root}/yolov8/runs/detect/latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8l.pt\")  # load a pretrained model (recommended for training)\n",
    "print(f\"1 using {model}\")\n",
    "results = model.train(data = yaml_path, epochs=20, imgsz=640, batch = 16, device='cpu',  save = True, cache = True, project=run ,name=\"train\" )\n",
    "print(f\"2 done training. Results saved in: {results.save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_run = run / \"train\"\n",
    "weights_path = last_run / \"weights\" / \"best.pt\"\n",
    "if not weights_path.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå Weights not found at {weights_path}\")\n",
    "\n",
    "print(f\"üß™ Testing first 100 .png images from: {weights_path}\")\n",
    "\n",
    "test_images = sorted(test_dir.glob(\"*.png\"))[:100]  # replace with your real test_dir\n",
    "model = YOLO(str(weights_path))\n",
    "results = model(\n",
    "    [str(p) for p in test_images],\n",
    "    save=True,\n",
    "    conf=0.25,\n",
    "    save_dir=f\"{run}/first_100_inference\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = model(test_dir, save=True, conf=0.25, stream = True)\n",
    "# print(f\"3 done testing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
